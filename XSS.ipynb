{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Conv2D, MaxPooling2D,Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv():\n",
    "    contents=[]\n",
    "    with open(\"XSS_dataset.csv\",'r') as f:\n",
    "        for line in f:\n",
    "            word = line.split('\\n')\n",
    "            sentence = word[0]\n",
    "            index , string = sentence.split(',',maxsplit=1)\n",
    "            sentence, label = string.rsplit(',',maxsplit=1)\n",
    "            #sentence = sentence.strip('\"')\n",
    "            contents += [[sentence , label]]\n",
    "\n",
    "\n",
    "    contents=contents[1:]\n",
    "    #print(contents)\n",
    "    global xssdf\n",
    "    xssdf = pd.DataFrame(contents,columns=['Sentence','Label'])\n",
    "    xssdf = xssdf.replace({'\\t': ''}, regex=True)\n",
    "    xssdf['Sentence'] = xssdf['Sentence'].astype(str)\n",
    "    xssdf['Label']=xssdf['Label'].astype(int)\n",
    "    \n",
    "    \n",
    "load_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = xssdf['Sentence']\n",
    "y = xssdf['Label'].values\n",
    "trainX, testX, trainY, testY = train_test_split(X,y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences=trainX.values\n",
    "test_sentences=testX.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_ascii(sentence):\n",
    "    sentence_ascii=[]\n",
    "\n",
    "    for i in sentence:\n",
    "       \n",
    "        if(ord(i)<8222):      # ”  :  8221\n",
    "            \n",
    "            if(ord(i)==8217): # ’  :  8217 \n",
    "                sentence_ascii.append(134)\n",
    "            \n",
    "            \n",
    "            if(ord(i)==8221): # ”  :  8221 \"\"\n",
    "                sentence_ascii.append(129)\n",
    "                \n",
    "            if(ord(i)==8220): # “  :  8220\n",
    "                sentence_ascii.append(130)\n",
    "                \n",
    "                \n",
    "            if(ord(i)==8216): # ‘  :  8216\n",
    "                sentence_ascii.append(131)\n",
    "                \n",
    "            if(ord(i)==8217): # ’  :  8217\n",
    "                sentence_ascii.append(132)\n",
    "            \n",
    "            if(ord(i)==8211): # –  :  8211\n",
    "                sentence_ascii.append(133)\n",
    "                \n",
    "                \n",
    "            \"\"\"\n",
    "            If values less than 128 store them else discard them\n",
    "            \"\"\"\n",
    "            if (ord(i)<=128):\n",
    "                    sentence_ascii.append(ord(i))\n",
    "    \n",
    "            else:\n",
    "                    pass\n",
    "            \n",
    "\n",
    "    zer=np.zeros((10000))\n",
    "\n",
    "    for i in range(len(sentence_ascii)):\n",
    "        zer[i]=sentence_ascii[i]\n",
    "\n",
    "    zer.shape=(100, 100)\n",
    "\n",
    "    return zer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(sentences):\n",
    "    arr=np.zeros((len(sentences),100,100))\n",
    " \n",
    "    for i in range(len(sentences)):\n",
    "\n",
    "        image=convert_to_ascii(sentences[i])\n",
    "\n",
    "        x=np.asarray(image,dtype='float')\n",
    "        image =  cv2.resize(x, dsize=(100,100), interpolation=cv2.INTER_CUBIC)\n",
    "        image/=128\n",
    "        arr[i]=image\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_arr = preprocessing(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_arr = preprocessing(test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape :  (10952, 100, 100, 1)\n",
      "Test data shape :  (2739, 100, 100, 1)\n"
     ]
    }
   ],
   "source": [
    "#Reshape data for input to CNN\n",
    "data = train_arr.reshape(train_arr.shape[0], 100, 100, 1)\n",
    "test_data = test_arr.reshape(test_arr.shape[0], 100, 100, 1)\n",
    "print(\"Train data shape : \",data.shape)\n",
    "print(\"Test data shape : \",test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A basic CNN Model\n",
    "\n",
    "model=tf.keras.models.Sequential([\n",
    "    \n",
    "    tf.keras.layers.Conv2D(64,(3,3), activation=tf.nn.relu, input_shape=(100,100,1)),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(128,(3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(256,(3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    \n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 98, 98, 64)        640       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 49, 49, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 47, 47, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 23, 23, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 21, 21, 256)       295168    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 10, 10, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25600)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               6553856   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,964,737\n",
      "Trainable params: 6,964,737\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2 \n",
    "train_y = keras.utils.np_utils.to_categorical(data, num_classes)\n",
    "test_y = keras.utils.np_utils.to_categorical(test_data, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "UnimplementedError",
     "evalue": "Graph execution error:\n\nDetected at node 'sequential/conv2d/Conv2D' defined at (most recent call last):\n    File \"C:\\Users\\prajw\\AppData\\Local\\Programs\\Python\\Python38\\lib\\runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\prajw\\AppData\\Local\\Programs\\Python\\Python38\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"d:\\jupyternotebooks\\pacmanenv\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"d:\\jupyternotebooks\\pacmanenv\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"d:\\jupyternotebooks\\pacmanenv\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 707, in start\n      self.io_loop.start()\n    File \"d:\\jupyternotebooks\\pacmanenv\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\prajw\\AppData\\Local\\Programs\\Python\\Python38\\lib\\asyncio\\base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"C:\\Users\\prajw\\AppData\\Local\\Programs\\Python\\Python38\\lib\\asyncio\\base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"C:\\Users\\prajw\\AppData\\Local\\Programs\\Python\\Python38\\lib\\asyncio\\events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"d:\\jupyternotebooks\\pacmanenv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 502, in dispatch_queue\n      await self.process_one()\n    File \"d:\\jupyternotebooks\\pacmanenv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 491, in process_one\n      await dispatch(*args)\n    File \"d:\\jupyternotebooks\\pacmanenv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 398, in dispatch_shell\n      await result\n    File \"d:\\jupyternotebooks\\pacmanenv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 722, in execute_request\n      reply_content = await reply_content\n    File \"d:\\jupyternotebooks\\pacmanenv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 389, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"d:\\jupyternotebooks\\pacmanenv\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"d:\\jupyternotebooks\\pacmanenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2863, in run_cell\n      result = self._run_cell(\n    File \"d:\\jupyternotebooks\\pacmanenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2909, in _run_cell\n      return runner(coro)\n    File \"d:\\jupyternotebooks\\pacmanenv\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"d:\\jupyternotebooks\\pacmanenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3106, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"d:\\jupyternotebooks\\pacmanenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3309, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"d:\\jupyternotebooks\\pacmanenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3369, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\prajw\\AppData\\Local\\Temp\\ipykernel_15044\\2836026047.py\", line 5, in <cell line: 5>\n      model_log = model.fit(data, trainY,\n    File \"d:\\jupyternotebooks\\pacmanenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"d:\\jupyternotebooks\\pacmanenv\\lib\\site-packages\\keras\\engine\\training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"d:\\jupyternotebooks\\pacmanenv\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"d:\\jupyternotebooks\\pacmanenv\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"d:\\jupyternotebooks\\pacmanenv\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step\n      outputs = model.train_step(data)\n    File \"d:\\jupyternotebooks\\pacmanenv\\lib\\site-packages\\keras\\engine\\training.py\", line 859, in train_step\n      y_pred = self(x, training=True)\n    File \"d:\\jupyternotebooks\\pacmanenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"d:\\jupyternotebooks\\pacmanenv\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"d:\\jupyternotebooks\\pacmanenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"d:\\jupyternotebooks\\pacmanenv\\lib\\site-packages\\keras\\engine\\sequential.py\", line 374, in call\n      return super(Sequential, self).call(inputs, training=training, mask=mask)\n    File \"d:\\jupyternotebooks\\pacmanenv\\lib\\site-packages\\keras\\engine\\functional.py\", line 451, in call\n      return self._run_internal_graph(\n    File \"d:\\jupyternotebooks\\pacmanenv\\lib\\site-packages\\keras\\engine\\functional.py\", line 589, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"d:\\jupyternotebooks\\pacmanenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"d:\\jupyternotebooks\\pacmanenv\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"d:\\jupyternotebooks\\pacmanenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"d:\\jupyternotebooks\\pacmanenv\\lib\\site-packages\\keras\\layers\\convolutional.py\", line 248, in call\n      outputs = self.convolution_op(inputs, self.kernel)\n    File \"d:\\jupyternotebooks\\pacmanenv\\lib\\site-packages\\keras\\layers\\convolutional.py\", line 233, in convolution_op\n      return tf.nn.convolution(\nNode: 'sequential/conv2d/Conv2D'\nDNN library is not found.\n\t [[{{node sequential/conv2d/Conv2D}}]] [Op:__inference_train_function_1178]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
      "Input \u001b[1;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m num_epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#model training\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m model_log \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainY\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m          \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m          \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m          \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m          \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mtestY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m                     \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\jupyternotebooks\\pacmanenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32md:\\jupyternotebooks\\pacmanenv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mUnimplementedError\u001b[0m: Graph execution error:\n\nDetected at node 'sequential/conv2d/Conv2D' defined at (most recent call last):\n    File \"C:\\Users\\prajw\\AppData\\Local\\Programs\\Python\\Python38\\lib\\runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\prajw\\AppData\\Local\\Programs\\Python\\Python38\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"d:\\jupyternotebooks\\pacmanenv\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"d:\\jupyternotebooks\\pacmanenv\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"d:\\jupyternotebooks\\pacmanenv\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 707, in start\n      self.io_loop.start()\n    File \"d:\\jupyternotebooks\\pacmanenv\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\prajw\\AppData\\Local\\Programs\\Python\\Python38\\lib\\asyncio\\base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"C:\\Users\\prajw\\AppData\\Local\\Programs\\Python\\Python38\\lib\\asyncio\\base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"C:\\Users\\prajw\\AppData\\Local\\Programs\\Python\\Python38\\lib\\asyncio\\events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"d:\\jupyternotebooks\\pacmanenv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 502, in dispatch_queue\n      await self.process_one()\n    File \"d:\\jupyternotebooks\\pacmanenv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 491, in process_one\n      await dispatch(*args)\n    File \"d:\\jupyternotebooks\\pacmanenv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 398, in dispatch_shell\n      await result\n    File \"d:\\jupyternotebooks\\pacmanenv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 722, in execute_request\n      reply_content = await reply_content\n    File \"d:\\jupyternotebooks\\pacmanenv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 389, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"d:\\jupyternotebooks\\pacmanenv\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"d:\\jupyternotebooks\\pacmanenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2863, in run_cell\n      result = self._run_cell(\n    File \"d:\\jupyternotebooks\\pacmanenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2909, in _run_cell\n      return runner(coro)\n    File \"d:\\jupyternotebooks\\pacmanenv\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"d:\\jupyternotebooks\\pacmanenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3106, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"d:\\jupyternotebooks\\pacmanenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3309, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"d:\\jupyternotebooks\\pacmanenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3369, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\prajw\\AppData\\Local\\Temp\\ipykernel_15044\\2836026047.py\", line 5, in <cell line: 5>\n      model_log = model.fit(data, trainY,\n    File \"d:\\jupyternotebooks\\pacmanenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"d:\\jupyternotebooks\\pacmanenv\\lib\\site-packages\\keras\\engine\\training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"d:\\jupyternotebooks\\pacmanenv\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"d:\\jupyternotebooks\\pacmanenv\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"d:\\jupyternotebooks\\pacmanenv\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step\n      outputs = model.train_step(data)\n    File \"d:\\jupyternotebooks\\pacmanenv\\lib\\site-packages\\keras\\engine\\training.py\", line 859, in train_step\n      y_pred = self(x, training=True)\n    File \"d:\\jupyternotebooks\\pacmanenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"d:\\jupyternotebooks\\pacmanenv\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"d:\\jupyternotebooks\\pacmanenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"d:\\jupyternotebooks\\pacmanenv\\lib\\site-packages\\keras\\engine\\sequential.py\", line 374, in call\n      return super(Sequential, self).call(inputs, training=training, mask=mask)\n    File \"d:\\jupyternotebooks\\pacmanenv\\lib\\site-packages\\keras\\engine\\functional.py\", line 451, in call\n      return self._run_internal_graph(\n    File \"d:\\jupyternotebooks\\pacmanenv\\lib\\site-packages\\keras\\engine\\functional.py\", line 589, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"d:\\jupyternotebooks\\pacmanenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"d:\\jupyternotebooks\\pacmanenv\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"d:\\jupyternotebooks\\pacmanenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"d:\\jupyternotebooks\\pacmanenv\\lib\\site-packages\\keras\\layers\\convolutional.py\", line 248, in call\n      outputs = self.convolution_op(inputs, self.kernel)\n    File \"d:\\jupyternotebooks\\pacmanenv\\lib\\site-packages\\keras\\layers\\convolutional.py\", line 233, in convolution_op\n      return tf.nn.convolution(\nNode: 'sequential/conv2d/Conv2D'\nDNN library is not found.\n\t [[{{node sequential/conv2d/Conv2D}}]] [Op:__inference_train_function_1178]"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_epoch = 10\n",
    "\n",
    "#model training\n",
    "model_log = model.fit(data, trainY,\n",
    "          batch_size=batch_size,\n",
    "          epochs=num_epoch,\n",
    "          verbose=1,\n",
    "          validation_data=( test_data,  testY)\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict for test set\n",
    "pred=model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold values predicted\n",
    "\n",
    "for i in range(len(pred)):\n",
    "    if pred[i]>0.5:\n",
    "        pred[i]=1\n",
    "    elif pred[i]<=0.5:\n",
    "        pred[i]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_function(tp,tn,fp,fn):\n",
    "    \n",
    "    accuracy = (tp+tn) / (tp+tn+fp+fn)\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "\n",
    "\n",
    "def precision_function(tp,fp):\n",
    "    \n",
    "    precision = tp / (tp+fp)\n",
    "    \n",
    "    return precision\n",
    "\n",
    "\n",
    "\n",
    "def recall_function(tp,fn):\n",
    "    \n",
    "    recall=tp / (tp+fn)\n",
    "    \n",
    "    return recall\n",
    "\n",
    "\n",
    "\n",
    "def confusion_matrix(truth,predicted):\n",
    "    \n",
    "    true_positive = 0\n",
    "    true_negative = 0\n",
    "    false_positive = 0\n",
    "    false_negative = 0\n",
    "    \n",
    "    for true,pred in zip(truth,predicted):\n",
    "        if true == 1:\n",
    "            if pred == true:\n",
    "                true_positive += 1\n",
    "            elif pred != true:\n",
    "                false_negative += 1\n",
    "\n",
    "        elif true == 0:\n",
    "            if pred == true:\n",
    "                true_negative += 1\n",
    "            elif pred != true:\n",
    "                false_positive += 1\n",
    "            \n",
    "    accuracy=accuracy_function(true_positive, true_negative, false_positive, false_negative)\n",
    "    precision=precision_function(true_positive, false_positive)\n",
    "    recall=recall_function(true_positive, false_negative)\n",
    "    confusion_matrix_res = [[true_negative, false_negative],[false_positive,true_positive]]\n",
    "    \n",
    "    return (accuracy,\n",
    "            precision,\n",
    "           recall,\n",
    "           confusion_matrix_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy,precision,recall, matrix =confusion_matrix(testY,pred)\n",
    "print(\" Accuracy : {0} \\n Precision : {1} \\n Recall : {2} \\n Confusion matrix: {3}\".format(accuracy, precision, recall, matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing(querystring):\n",
    "    instance=[]\n",
    "    instance = testX\n",
    "    instance = instance[:250]\n",
    "    instance[-1] = querystring[0]\n",
    "    test_instance=instance.values\n",
    "    instance_arr = preprocessing(test_instance)\n",
    "    instance_data = instance_arr.reshape(instance_arr.shape[0], 100, 100, 1)\n",
    "    pred=loaded_model.predict(instance_data)\n",
    "    if pred[-1]>0.5:\n",
    "            res=1\n",
    "    else:\n",
    "            res=0\n",
    "\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"xssmodel.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"xssmodel.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "# load json and create model\n",
    "json_file = open('xssmodel.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"xssmodel.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hello world!\n",
    "#<script>alert(document.cookie())</script>\n",
    "testing(['architha aaa'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
